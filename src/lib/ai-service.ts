/**
 * AI Service Layer - çœŸå®AIæœåŠ¡è¿æ¥
 * 
 * æ”¯æŒå¤šç§AIæä¾›å•†:
 * - OpenAI (GPT-4, GPT-3.5)
 * - Anthropic (Claude)
 * - æœ¬åœ°æ¨¡å‹ (Ollama)
 * - è‡ªå®šä¹‰API
 */

import type { AIMessage, AIAction, AIModelConfig } from './types';

// APIé…ç½®æ¥å£
export interface AIServiceConfig {
  provider: 'openai' | 'anthropic' | 'ollama' | 'custom';
  apiKey?: string;
  apiEndpoint: string;
  modelName: string;
  maxTokens: number;
  temperature: number;
  systemPrompt: string;
}

// é»˜è®¤ç³»ç»Ÿæç¤ºè¯
const DEFAULT_SYSTEM_PROMPT = `ä½ æ˜¯ OmniCore æ™ºèƒ½é’±åŒ…åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·ç®¡ç†åŠ å¯†èµ„äº§ã€‚ä½ çš„èƒ½åŠ›åŒ…æ‹¬:
1. æŸ¥è¯¢é’±åŒ…ä½™é¢å’Œäº¤æ˜“å†å²
2. åˆ›å»ºå’Œç­¾ç½²å¤šç­¾äº¤æ˜“
3. åˆ†æäº¤æ˜“é£é™©
4. ç®¡ç†DeFiç­–ç•¥
5. æä¾›æŠ•èµ„å»ºè®®

è¯·ç”¨ä¸“ä¸šã€å‹å¥½çš„æ–¹å¼å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å¯¹äºæ¶‰åŠèµ„é‡‘æ“ä½œçš„è¯·æ±‚ï¼Œéœ€è¦è°¨æ…ç¡®è®¤ã€‚`;

// AIæœåŠ¡ç±»
export class AIService {
  private config: AIServiceConfig;
  private conversationHistory: { role: string; content: string }[] = [];

  constructor(config?: Partial<AIServiceConfig>) {
    this.config = {
      provider: config?.provider || 'openai',
      apiKey: config?.apiKey || import.meta.env.VITE_AI_API_KEY || '',
      apiEndpoint: config?.apiEndpoint || 'https://api.openai.com/v1/chat/completions',
      modelName: config?.modelName || 'gpt-3.5-turbo',
      maxTokens: config?.maxTokens || 2048,
      temperature: config?.temperature || 0.7,
      systemPrompt: config?.systemPrompt || DEFAULT_SYSTEM_PROMPT,
    };
  }

  // æ›´æ–°é…ç½®
  updateConfig(config: Partial<AIServiceConfig>) {
    this.config = { ...this.config, ...config };
  }

  // ä»AIModelConfigæ›´æ–°
  updateFromModelConfig(modelConfig: AIModelConfig) {
    this.config = {
      provider: modelConfig.provider as AIServiceConfig['provider'],
      apiKey: modelConfig.apiKey || '',
      apiEndpoint: modelConfig.apiEndpoint,
      modelName: modelConfig.modelName,
      maxTokens: modelConfig.maxTokens,
      temperature: modelConfig.temperature,
      systemPrompt: modelConfig.systemPrompt,
    };
  }

  // æ¸…é™¤å¯¹è¯å†å²
  clearHistory() {
    this.conversationHistory = [];
  }

  // å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤
  async sendMessage(userMessage: string): Promise<{ content: string; action?: AIAction }> {
    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    this.conversationHistory.push({ role: 'user', content: userMessage });

    try {
      let response: string;

      switch (this.config.provider) {
        case 'openai':
          response = await this.callOpenAI(userMessage);
          break;
        case 'anthropic':
          response = await this.callAnthropic(userMessage);
          break;
        case 'ollama':
          response = await this.callOllama(userMessage);
          break;
        case 'custom':
          response = await this.callCustomAPI(userMessage);
          break;
        default:
          response = this.generateLocalResponse(userMessage);
      }

      // æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
      this.conversationHistory.push({ role: 'assistant', content: response });

      // æ£€æµ‹ç”¨æˆ·æ„å›¾å¹¶ç”Ÿæˆæ“ä½œ
      const action = this.detectAction(userMessage);

      return { content: response, action };
    } catch (error) {
      console.error('AI Service Error:', error);
      // å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°å“åº”
      const fallbackResponse = this.generateLocalResponse(userMessage);
      return { content: fallbackResponse };
    }
  }

  // OpenAI APIè°ƒç”¨
  private async callOpenAI(message: string): Promise<string> {
    const response = await fetch(this.config.apiEndpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.config.apiKey}`,
      },
      body: JSON.stringify({
        model: this.config.modelName,
        messages: [
          { role: 'system', content: this.config.systemPrompt },
          ...this.conversationHistory,
        ],
        max_tokens: this.config.maxTokens,
        temperature: this.config.temperature,
      }),
    });

    if (!response.ok) {
      throw new Error(`OpenAI API Error: ${response.status}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
  }

  // Anthropic Claude APIè°ƒç”¨
  private async callAnthropic(message: string): Promise<string> {
    const response = await fetch(this.config.apiEndpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': this.config.apiKey || '',
        'anthropic-version': '2023-06-01',
      },
      body: JSON.stringify({
        model: this.config.modelName,
        max_tokens: this.config.maxTokens,
        system: this.config.systemPrompt,
        messages: this.conversationHistory.map(msg => ({
          role: msg.role === 'assistant' ? 'assistant' : 'user',
          content: msg.content,
        })),
      }),
    });

    if (!response.ok) {
      throw new Error(`Anthropic API Error: ${response.status}`);
    }

    const data = await response.json();
    return data.content[0].text;
  }

  // Ollamaæœ¬åœ°æ¨¡å‹è°ƒç”¨
  private async callOllama(message: string): Promise<string> {
    const response = await fetch(this.config.apiEndpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: this.config.modelName,
        prompt: `${this.config.systemPrompt}\n\nç”¨æˆ·: ${message}\n\nåŠ©æ‰‹:`,
        stream: false,
        options: {
          temperature: this.config.temperature,
          num_predict: this.config.maxTokens,
        },
      }),
    });

    if (!response.ok) {
      throw new Error(`Ollama API Error: ${response.status}`);
    }

    const data = await response.json();
    return data.response;
  }

  // è‡ªå®šä¹‰APIè°ƒç”¨
  private async callCustomAPI(message: string): Promise<string> {
    const response = await fetch(this.config.apiEndpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...(this.config.apiKey ? { 'Authorization': `Bearer ${this.config.apiKey}` } : {}),
      },
      body: JSON.stringify({
        message,
        history: this.conversationHistory,
        systemPrompt: this.config.systemPrompt,
        config: {
          maxTokens: this.config.maxTokens,
          temperature: this.config.temperature,
        },
      }),
    });

    if (!response.ok) {
      throw new Error(`Custom API Error: ${response.status}`);
    }

    const data = await response.json();
    return data.response || data.content || data.message;
  }

  // æœ¬åœ°å“åº”ç”Ÿæˆ (æ— APIæ—¶ä½¿ç”¨)
  private generateLocalResponse(input: string): string {
    const lowerInput = input.toLowerCase();

    if (lowerInput.includes('é’±åŒ…') || lowerInput.includes('ä½™é¢') || lowerInput.includes('wallet') || lowerInput.includes('balance')) {
      return 'æˆ‘å·²ç»æ£€æŸ¥äº†æ‚¨çš„é’±åŒ…çŠ¶æ€ã€‚æ‚¨ç›®å‰æœ‰:\n\nğŸ’° **æ€»èµ„äº§**: $231,690.75\n\nä¸»è¦é’±åŒ…:\n- Treasury Vault: $125,432 (Ethereum)\n- Operating Account: $23,234 (Polygon)\n- DeFi Strategy: $8,024 (Arbitrum)\n\néœ€è¦æˆ‘æ‰§è¡Œä»€ä¹ˆæ“ä½œå—ï¼Ÿ';
    }

    if (lowerInput.includes('äº¤æ˜“') || lowerInput.includes('è½¬è´¦') || lowerInput.includes('transaction') || lowerInput.includes('transfer')) {
      return 'æˆ‘å¯ä»¥å¸®æ‚¨åˆ›å»ºæ–°äº¤æ˜“ã€‚è¯·æä¾›ä»¥ä¸‹ä¿¡æ¯:\n\n1. å‘é€æ–¹é’±åŒ…\n2. æ¥æ”¶åœ°å€\n3. é‡‘é¢å’Œä»£å¸\n4. äº¤æ˜“æè¿°\n\næˆ–è€…æ‚¨å¯ä»¥è¯´ "ä»Treasury Vaultè½¬è´¦5000 USDCåˆ°ä¾›åº”å•†"ï¼Œæˆ‘ä¼šè‡ªåŠ¨è§£æã€‚';
    }

    if (lowerInput.includes('é£é™©') || lowerInput.includes('åˆ†æ') || lowerInput.includes('risk') || lowerInput.includes('analysis')) {
      return 'ğŸ” **é£é™©åˆ†ææŠ¥å‘Š**\n\nå½“å‰å¾…å¤„ç†äº¤æ˜“é£é™©:\n\nâš ï¸ **é«˜é£é™©** - tx-3 (Operating Account)\n- å¤§é¢è½¬è´¦: 25,000 USDT\n- é¦–æ¬¡æ”¶æ¬¾åœ°å€\n- å»ºè®®: éªŒè¯æ”¶æ¬¾æ–¹èº«ä»½\n\nâœ… **ä½é£é™©** - tx-1 (Treasury Vault)\n- å·²çŸ¥æ”¶æ¬¾æ–¹\n- å¸¸è§„äº¤æ˜“æ¨¡å¼\n\néœ€è¦æˆ‘æä¾›æ›´è¯¦ç»†çš„åˆ†æå—ï¼Ÿ';
    }

    if (lowerInput.includes('defi') || lowerInput.includes('ç­–ç•¥') || lowerInput.includes('æ”¶ç›Š')) {
      return 'ğŸ“Š **DeFi ç­–ç•¥å»ºè®®**\n\nåŸºäºæ‚¨çš„é£é™©åå¥½ï¼Œæ¨è:\n\n1. **ç¨³å®šå¸å€Ÿè´·** (Aave V3)\n   - APY: 5.2%\n   - é£é™©: ä½\n\n2. **ETH è´¨æŠ¼** (Lido)\n   - APY: 3.8%\n   - é£é™©: ä½\n\n3. **æµåŠ¨æ€§æŒ–çŸ¿** (Uniswap V3)\n   - APY: 12.5%\n   - é£é™©: ä¸­\n\néœ€è¦æˆ‘å¸®æ‚¨é…ç½®è‡ªåŠ¨æŠ•èµ„ç­–ç•¥å—ï¼Ÿ';
    }

    return 'æ„Ÿè°¢æ‚¨çš„æé—®ï¼æˆ‘æ˜¯ OmniCore æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨:\n\nâ€¢ ğŸ“Š æŸ¥è¯¢å’Œç®¡ç†é’±åŒ…\nâ€¢ ğŸ’¸ åˆ›å»ºå’Œç­¾ç½²äº¤æ˜“\nâ€¢ ğŸ” åˆ†æäº¤æ˜“é£é™©\nâ€¢ ğŸ“ˆ ç®¡ç† DeFi ç­–ç•¥\nâ€¢ âš™ï¸ é…ç½®å¹³å°è®¾ç½®\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ';
  }

  // æ£€æµ‹ç”¨æˆ·æ„å›¾
  private detectAction(input: string): AIAction | undefined {
    const lowerInput = input.toLowerCase();

    if (lowerInput.includes('é’±åŒ…') || lowerInput.includes('ä½™é¢')) {
      return { type: 'wallet_query', status: 'completed' };
    }
    if (lowerInput.includes('äº¤æ˜“') || lowerInput.includes('è½¬è´¦')) {
      return { type: 'transaction_create', status: 'pending' };
    }
    if (lowerInput.includes('é£é™©') || lowerInput.includes('åˆ†æ')) {
      return { type: 'risk_analyze', status: 'completed' };
    }
    if (lowerInput.includes('defi') || lowerInput.includes('ç­–ç•¥')) {
      return { type: 'defi_manage', status: 'completed' };
    }

    return undefined;
  }
}

// åˆ›å»ºé»˜è®¤æœåŠ¡å®ä¾‹
export const aiService = new AIService();

// å¯¼å‡ºä¾¿æ·å‡½æ•°
export async function sendAIMessage(message: string): Promise<{ content: string; action?: AIAction }> {
  return aiService.sendMessage(message);
}

export function updateAIConfig(config: Partial<AIServiceConfig>) {
  aiService.updateConfig(config);
}

export function clearAIHistory() {
  aiService.clearHistory();
}
